{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import json\n",
    "import datetime\n",
    "import head_model\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from transformers import MLukeTokenizer, LukeConfig, LukeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:4000/\")\n",
    "mlflow.set_experiment(\"Ner-Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tag_values = ['PAD', 'ADDRESS', 'EMAIL','PERSON','PHONENUMBER','MISCELLANEOUS','PERSONTYPE',\n",
    "              'ORGANIZATION','PRODUCT','IP','LOCATION','O','DATETIME', 'URL']\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['xlmr_linear', 'xlmr_crf', 'mluke_linear', 'mluke_crf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xlm-roberta-base'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['models']['xlmr_linear']['pre_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = config['models'][model_names[0]]['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.47"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"f2_span_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022/02/14 11:22:59 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2022/02/14 11:23:03 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022/02/14 11:23:23 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2022/02/14 11:23:26 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Some weights of the model checkpoint at studio-ousia/mluke-base were not used when initializing LukeModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'entity_predictions.transform.dense.bias', 'entity_predictions.transform.dense.weight', 'entity_predictions.transform.LayerNorm.weight', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022/02/14 11:24:01 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2022/02/14 11:24:07 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Some weights of the model checkpoint at studio-ousia/mluke-base were not used when initializing LukeModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'entity_predictions.transform.dense.bias', 'entity_predictions.transform.dense.weight', 'entity_predictions.transform.LayerNorm.weight', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022/02/14 11:24:45 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2022/02/14 11:24:49 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.2+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.10.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    if \"xlmr\" in model_name:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config['models'][model_name]['pre_train'], do_lower_case=False,use_fast=False)\n",
    "        model_config = AutoConfig.from_pretrained(config['models'][model_name]['pre_train'], output_hidden_states=True)\n",
    "        model_config.hidden_dropout_prob = config['models'][model_name]['params']['bert_hidd_dropout']\n",
    "        model_config.attention_probs_dropout_prob = config['models'][model_name]['params']['bert_att_dropout']\n",
    "        base_model = AutoModel.from_pretrained(config['models'][model_name]['pre_train'], config=model_config)\n",
    "    elif \"mluke\" in model_name:\n",
    "        tokenizer = MLukeTokenizer.from_pretrained(config['models'][model_name]['pre_train'], do_lower_case=False,use_fast=False)\n",
    "        model_config = LukeConfig.from_pretrained(config['models'][model_name]['pre_train'], output_hidden_states=True)\n",
    "        model_config.hidden_dropout_prob = config['models'][model_name]['params']['bert_hidd_dropout']\n",
    "        model_config.attention_probs_dropout_prob = config['models'][model_name]['params']['bert_att_dropout']\n",
    "        base_model = LukeModel.from_pretrained(config['models'][model_name]['pre_train'], config=model_config)\n",
    "\n",
    "    if \"linear\" in model_name:\n",
    "        model = head_model.BaseBertSoftmax(model=base_model, drop_out=config['models'][model_name]['params']['linear_dropout'], num_labels=len(tag_values))\n",
    "        model.to(device)\n",
    "    elif \"crf\" in model_name:\n",
    "        model = head_model.BaseBertCrf(model=base_model, drop_out=config['models'][model_name]['params']['linear_dropout'], num_labels=len(tag_values))\n",
    "        model.to(device)\n",
    "    params = config['models'][model_name]['params']\n",
    "    tag = {\"data\": config['data'], \"model\": model_name}\n",
    "    runname = model_name + str(datetime.datetime.now()).replace(\" \",\"T\")\n",
    "    with mlflow.start_run(run_name=runname) as run:\n",
    "        mlflow.set_tags(tag)                                    # Tags to help in tracking\n",
    "\n",
    "        metrics = config['models'][model_name]['metrics']\n",
    "        mlflow.log_params(params)                               # Log params/hyperparameters used in experiement\n",
    "        \n",
    "        mlflow.log_metric(\"f2_span_train\", metrics[\"f2_span_train\"])\n",
    "        mlflow.log_metric(\"f2_span_dev\", metrics[\"f2_span_dev\"])\n",
    "        mlflow.log_metric(\"f2_span_test\", metrics[\"f2_span_test\"])\n",
    "        \n",
    "        #signature = infer_signature(X, model.predict(X))\n",
    "        mlflow.pytorch.log_model(model, artifact_path=\"models\")\n",
    "        #mlflow.sklearn.log_model(model, artifact_path=\"models\", signature=signature) # Log model created\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "560a0688592f1e135833133de6adb42b9cb9012b086646fa70cf9c4127a0b6d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('NER')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
